{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text\n",
    "from pandarallel import pandarallel\n",
    "import regex as re\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "from pyLDAvis import gensim_models\n",
    "import gensim.corpora as corpora\n",
    "import pyLDAvis.gensim_models\n",
    "import os\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql+psycopg2://postgres:4750@192.168.0.137:5432/ba1')\n",
    "\n",
    "def sql_read(topics,lim):\n",
    "    stat= \"SELECT record_id, collectiontitle_token,abstract_token,title_token,class FROM  ke_stage.ba_corpus_2 WHERE class LIKE \"+str(topics)+\" LIMIT \" +str(lim)\n",
    "    df = pd.read_sql_query(sqlalchemy.text(str(stat)),engine)\n",
    "    return df\n",
    "\n",
    "def to_data(df):\n",
    "    data=[]\n",
    "    for row in tqdm(df['combined'].values):\n",
    "        row = row.split(\",\")\n",
    "        data.append(row)\n",
    "    return data\n",
    "def to_id_corpus(data):\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(data)\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in data]\n",
    "    return corpus, id2word\n",
    "\n",
    "def row2data(row):\n",
    "    data=[]\n",
    "    row = row.split(\",\")\n",
    "    data.append(row)\n",
    "    return data\n",
    "\n",
    "def get_topic(row ,lda):\n",
    "    to_pro = []\n",
    "    data = row2data(row)\n",
    "    corpus, id2w = to_id_corpus(data)\n",
    "    \n",
    "    topic = lda.get_document_topics(corpus, minimum_probability=0.5, minimum_phi_value=None,\n",
    "                                   per_word_topics=False)\n",
    "    for t in topic:\n",
    "            to_pro.append(t)\n",
    "    return(to_pro)\n",
    "\n",
    "def count_class_pop(df):\n",
    "    counted=df['class'].value_counts()\n",
    "    counted = counted.to_frame()\n",
    "    counted[\"population\"] = counted['class'].values / len(df)\n",
    "    counted[\"pop_perc\"] = counted['population'].values * 100\n",
    "    #ax = sns.barplot(data=counted,x=\"pop_perc\",  y= counted.index, orient=\"h\")\n",
    "    #ax.set(xlabel=\"Anteil der Publikation in %\",ylabel=\"Klasse\")\n",
    "    #plt.show()\n",
    "    lowest_c = counted.min()['class']\n",
    "    return counted , lowest_c\n",
    "\n",
    "def combine_tokens(df):\n",
    "    df['combined'] = df[df.columns[1:3]].parallel_apply(lambda x: ','.join(x.astype(str)),axis=1)\n",
    "    df = df.drop(['title_token',\n",
    "                'abstract_token','collectiontitle_token'\n",
    "                ],axis =1 )\n",
    "    df = df[df[\"combined\"].str.len() > 3]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2cd2def9894be9bbcbb48e7cab6438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2357), Label(value='0 / 2357'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5310/5310 [00:00<00:00, 153697.94it/s]\n",
      "100%|██████████| 1770/1770 [00:00<00:00, 196498.72it/s]\n",
      "100%|██████████| 1770/1770 [00:00<00:00, 14386.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1770/1770 [00:00<00:00, 12457.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1770/1770 [00:00<00:00, 12609.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5310/5310 [00:00<00:00, 165508.04it/s]\n",
      "100%|██████████| 1770/1770 [00:00<00:00, 173813.40it/s]\n",
      "100%|██████████| 1770/1770 [00:00<00:00, 14242.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1770/1770 [00:00<00:00, 14358.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1770/1770 [00:00<00:00, 13615.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:00<00:00, 162117.50it/s]\n",
      "100%|██████████| 1250/1250 [00:00<00:00, 249768.00it/s]\n",
      "100%|██████████| 1250/1250 [00:00<00:00, 14547.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:00<00:00, 11008.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:00<00:00, 5323.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:00<00:00, 151592.58it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 178208.02it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 14549.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:00<00:00, 12425.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:00<00:00, 10884.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 936/936 [00:00<00:00, 133587.47it/s]\n",
      "100%|██████████| 312/312 [00:00<00:00, 102412.18it/s]\n",
      "100%|██████████| 312/312 [00:00<00:00, 13191.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:00<00:00, 14607.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:00<00:00, 13895.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [00:00<00:00, 116910.92it/s]\n",
      "100%|██████████| 156/156 [00:00<00:00, 155936.95it/s]\n",
      "100%|██████████| 156/156 [00:00<00:00, 14134.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:00<00:00, 13547.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:00<00:00, 13547.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lim=5000\n",
    "size=lim\n",
    "df_med = sql_read(\"'Medizin'\",lim)                 \n",
    "df_land = sql_read(\"'Landwirtschaft'\",lim)          \n",
    "df_umwelt = sql_read(\"'Umweltwissenschaften'\",lim)     \n",
    "df_ern = sql_read(\"'ErnÃ¤hrung'\",lim)     \n",
    "df = pd.concat([df_med, df_land,df_umwelt,df_ern])\n",
    "df = df.replace('', np.nan)\n",
    "df = df.drop(df[pd.isna(df['collectiontitle_token']) & pd.isna(df['abstract_token']) & pd.isna(df['title_token'])].index)\n",
    "df = df.replace(np.nan,'')\n",
    "df = combine_tokens(df)\n",
    "\n",
    "while size > 1000:\n",
    "    size = int(size)\n",
    "    df_med = df.loc[df['class'] == \"Medizin\"].head(int(size))\n",
    "    df_land = df.loc[df['class'] =='Landwirtschaft'].head(int(size))         \n",
    "    df_umwelt = df.loc[df['class'] =='Umweltwissenschaften'].head(int(size))  \n",
    "    df_ern = df.loc[df['class'] =='ErnÃ¤hrung'].head(int(size))            \n",
    "    df = pd.concat([df_med, df_land,df_umwelt,df_ern])\n",
    "    counted, lowest_c = count_class_pop(df)\n",
    "    df_med = df.loc[df['class'] == \"Medizin\"].head(int(lowest_c))\n",
    "    df_land = df.loc[df['class'] =='Landwirtschaft'].head(int(lowest_c))         \n",
    "    df_umwelt = df.loc[df['class'] =='Umweltwissenschaften'].head(int(lowest_c))  \n",
    "    df_ern = df.loc[df['class'] =='ErnÃ¤hrung'].head(int(lowest_c))            \n",
    "    df = pd.concat([df_med, df_land,df_umwelt,df_ern])\n",
    "    counted, lowest_c = count_class_pop(df)\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=0.25)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    train_data = to_data(df_train)\n",
    "    test_data = to_data(df_test)\n",
    "    train_corpus, train_id2w = to_id_corpus(train_data)\n",
    "    test_corpus, test_id2w = to_id_corpus(test_data)\n",
    "    num_topics = 4\n",
    "    while num_topics < 13:\n",
    "        lda = gensim.models.ldamulticore.LdaMulticore(\n",
    "                                corpus=train_corpus,\n",
    "                                num_topics=num_topics,\n",
    "                                id2word=train_id2w,\n",
    "                                chunksize=1000,\n",
    "                                workers=15, # Num. Processing Cores - 1\n",
    "                                passes=20,\n",
    "                                eval_every = 2,\n",
    "                                per_word_topics=False)\n",
    "        df_test[\"topic\"] = df_test[\"combined\"].apply(lambda x: get_topic(x , lda))\n",
    "        df_test[\"topic\"] = df_test[\"topic\"].astype(\"str\")\n",
    "        df_test[\"topic\"] = df_test[\"topic\"].replace(to_replace=r'[^\\d|\\.|\\,]', value='', regex=True)\n",
    "        df_test[\"topic\"] = df_test[\"topic\"].replace('', np.nan)\n",
    "        df_test[[\"topic\",\"certainty\"]] =  df_test[\"topic\"].progress_apply(lambda x: pd.Series(str(x).split(\",\")))\n",
    "        count_series =  df_test.groupby(['class','topic'])['class'].count()\n",
    "        count_series = count_series.to_frame()\n",
    "        count_series.columns = ['count']\n",
    "        count_series = count_series.reset_index()\n",
    "        print(\"Anzahl der Publiktationen pro Klasse:\" ,int(lowest_c))\n",
    "        ax = sns.barplot(data=count_series,x=\"count\",  y=\"class\", orient=\"h\", hue=\"topic\")\n",
    "        ax.set(xlabel=\"Menge an Zugewiesenen Topics pro Klasse\",ylabel=\"Klasse(Averbis) & Topic(LDA)\")\n",
    "        ax.text(x=0.5, y=1.1, s='Klassifzierungsgenauigkeit des LDA Models anhand des Testdatensatzes',\n",
    "                fontsize=13, weight='bold',\n",
    "                ha='center', va='bottom', transform=ax.transAxes)\n",
    "        ax.text(x=0.5, y=1.05, s=\"bei einer Testdatensatzgröße von \" + str(len(df_test))+ \" Publikationen und \"+ str(num_topics)+' \"Topics\"',\n",
    "                fontsize=8, alpha=0.75, ha='center', va='bottom', transform=ax.transAxes)\n",
    "        \n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig(\"grafiken\\\\Klasse_zu_pub_\"+str(size)+\"_topics_\"+str(num_topics)+\".png\",dpi=300, bbox_inches = \"tight\") \n",
    "        fig.clf()\n",
    "        count_series.to_csv(\"lda_score_csv\\\\topic_population_at_\"+str(size)+\"_topics_\"+str(num_topics)+\".csv\")\n",
    "        num_topics = num_topics + 4\n",
    "\n",
    "    size = size/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
