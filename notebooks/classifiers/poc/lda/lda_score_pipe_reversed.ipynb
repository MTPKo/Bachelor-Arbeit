{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text\n",
    "from pandarallel import pandarallel\n",
    "import regex as re\n",
    "pandarallel.initialize(progress_bar=False, nb_workers= 8)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "from pyLDAvis import gensim_models\n",
    "import gensim.corpora as corpora\n",
    "import pyLDAvis.gensim_models\n",
    "import os\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql+psycopg2://postgres:4750@192.168.0.137:5432/ba1')\n",
    "\n",
    "def sql_read(topics,lim):\n",
    "    stat= \"SELECT record_id, collectiontitle_token,abstract_token,title_token,class FROM  ke_stage.ba_corpus_2 WHERE class LIKE \"+str(topics)+\" LIMIT \" +str(lim)\n",
    "    df = pd.read_sql_query(sqlalchemy.text(str(stat)),engine)\n",
    "    return df\n",
    "\n",
    "def to_data(df):\n",
    "    data=[]\n",
    "    for row in tqdm(df['combined'].values):\n",
    "        row = row.split(\",\")\n",
    "        data.append(row)\n",
    "    return data\n",
    "def to_id_corpus(data):\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(data)\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in data]\n",
    "    return corpus, id2word\n",
    "\n",
    "def row2data(row):\n",
    "    data=[]\n",
    "    row = row.split(\",\")\n",
    "    data.append(row)\n",
    "    return data\n",
    "\n",
    "def get_topic(row ,lda):\n",
    "    to_pro = []\n",
    "    data = row2data(row)\n",
    "    corpus, id2w = to_id_corpus(data)\n",
    "    \n",
    "    topic = lda.get_document_topics(corpus, minimum_probability=0.5, minimum_phi_value=None,\n",
    "                                   per_word_topics=False)\n",
    "    for t in topic:\n",
    "            to_pro.append(t)\n",
    "    return(to_pro)\n",
    "\n",
    "def count_class_pop(df):\n",
    "    counted=df['class'].value_counts()\n",
    "    counted = counted.to_frame()\n",
    "    counted[\"population\"] = counted['class'].values / len(df)\n",
    "    counted[\"pop_perc\"] = counted['population'].values * 100\n",
    "    #ax = sns.barplot(data=counted,x=\"pop_perc\",  y= counted.index, orient=\"h\")\n",
    "    #ax.set(xlabel=\"Anteil der Publikation in %\",ylabel=\"Klasse\")\n",
    "    #plt.show()\n",
    "    lowest_c = counted.min()['class']\n",
    "    return counted , lowest_c\n",
    "\n",
    "def combine_tokens(df):\n",
    "    df['combined'] = df[df.columns[1:3]].parallel_apply(lambda x: ','.join(x.astype(str)),axis=1)\n",
    "    df = df.drop(['title_token',\n",
    "                'abstract_token','collectiontitle_token'\n",
    "                ],axis =1 )\n",
    "    df = df[df[\"combined\"].str.len() > 3]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading  1000  Einträge aus der Datenbank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:00<00:00, 64841.34it/s]\n",
      "100%|██████████| 281/281 [00:00<00:00, 70263.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainiere LDA Model mit  16  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281/281 [00:00<00:00, 4844.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 281  und  16  Topics\n",
      "trainiere LDA Model mit  20  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281/281 [00:00<00:00, 5854.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 281  und  20  Topics\n",
      "trainiere LDA Model mit  24  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281/281 [00:00<00:00, 5619.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 281  und  24  Topics\n",
      "loading  4000  Einträge aus der Datenbank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3888/3888 [00:00<00:00, 68210.91it/s]\n",
      "100%|██████████| 1296/1296 [00:00<00:00, 86404.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainiere LDA Model mit  16  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1296/1296 [00:00<00:00, 5837.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 1296  und  16  Topics\n",
      "trainiere LDA Model mit  20  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1296/1296 [00:00<00:00, 5785.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 1296  und  20  Topics\n",
      "trainiere LDA Model mit  24  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1296/1296 [00:00<00:00, 1357.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 1296  und  24  Topics\n",
      "loading  16000  Einträge aus der Datenbank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16335/16335 [00:00<00:00, 49054.34it/s]\n",
      "100%|██████████| 5445/5445 [00:00<00:00, 61875.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainiere LDA Model mit  16  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5445/5445 [00:00<00:00, 5544.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 5445  und  16  Topics\n",
      "trainiere LDA Model mit  20  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5445/5445 [00:01<00:00, 2775.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 5445  und  20  Topics\n",
      "trainiere LDA Model mit  24  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5445/5445 [00:00<00:00, 5500.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 5445  und  24  Topics\n",
      "loading  64000  Einträge aus der Datenbank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65130/65130 [00:01<00:00, 43623.33it/s]\n",
      "100%|██████████| 21710/21710 [00:01<00:00, 19753.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainiere LDA Model mit  16  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21710/21710 [00:07<00:00, 2927.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 21710  und  16  Topics\n",
      "trainiere LDA Model mit  20  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21710/21710 [00:07<00:00, 2877.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 21710  und  20  Topics\n",
      "trainiere LDA Model mit  24  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21710/21710 [00:06<00:00, 3143.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 21710  und  24  Topics\n",
      "loading  256000  Einträge aus der Datenbank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263058/263058 [00:06<00:00, 40220.61it/s]\n",
      "100%|██████████| 87686/87686 [00:01<00:00, 68293.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainiere LDA Model mit  16  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87686/87686 [00:29<00:00, 3001.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 87686  und  16  Topics\n",
      "trainiere LDA Model mit  20  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87686/87686 [00:35<00:00, 2471.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 87686  und  20  Topics\n",
      "trainiere LDA Model mit  24  Topics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87686/87686 [00:34<00:00, 2518.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Publiktationen pro Klasse: 87686  und  24  Topics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_df_size = 1000000\n",
    "min_df_size = 1000\n",
    "\n",
    "modi = 4\n",
    "\n",
    "while min_df_size < max_df_size:\n",
    "    lim=min_df_size    \n",
    "    print(\"loading \", int(lim),\" Einträge aus der Datenbank\")\n",
    "    df_med = sql_read(\"'Medizin'\",lim)                 \n",
    "    df_land = sql_read(\"'Landwirtschaft'\",lim)          \n",
    "    df_umwelt = sql_read(\"'Umweltwissenschaften'\",lim)     \n",
    "    df_ern = sql_read(\"'ErnÃ¤hrung'\",lim)     \n",
    "    df = pd.concat([df_med, df_land,df_umwelt,df_ern])\n",
    "    df = df.replace('', np.nan)\n",
    "    df = df.drop(df[pd.isna(df['collectiontitle_token']) & pd.isna(df['abstract_token']) & pd.isna(df['title_token'])].index)\n",
    "    df = df.replace(np.nan,'')\n",
    "    df = combine_tokens(df)\n",
    "\n",
    "    min_df_size = int(min_df_size)\n",
    "    df_med = df.loc[df['class'] == \"Medizin\"].head(int(min_df_size))\n",
    "    df_land = df.loc[df['class'] =='Landwirtschaft'].head(int(min_df_size))         \n",
    "    df_umwelt = df.loc[df['class'] =='Umweltwissenschaften'].head(int(min_df_size))  \n",
    "    df_ern = df.loc[df['class'] =='ErnÃ¤hrung'].head(int(min_df_size))            \n",
    "    df = pd.concat([df_med, df_land,df_umwelt,df_ern])\n",
    "    counted, lowest_c = count_class_pop(df)\n",
    "    df_med = df.loc[df['class'] == \"Medizin\"].head(int(lowest_c))\n",
    "    df_land = df.loc[df['class'] =='Landwirtschaft'].head(int(lowest_c))         \n",
    "    df_umwelt = df.loc[df['class'] =='Umweltwissenschaften'].head(int(lowest_c))  \n",
    "    df_ern = df.loc[df['class'] =='ErnÃ¤hrung'].head(int(lowest_c))            \n",
    "    df = pd.concat([df_med, df_land,df_umwelt,df_ern])\n",
    "    counted, lowest_c = count_class_pop(df)\n",
    "\n",
    "    df_train, df_test = train_test_split(df, test_size=0.25)\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    df_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    train_data = to_data(df_train)\n",
    "    test_data = to_data(df_test)\n",
    "    train_corpus, train_id2w = to_id_corpus(train_data)\n",
    "    test_corpus, test_id2w = to_id_corpus(test_data)\n",
    "    num_topics = 16\n",
    "    while num_topics < 25:\n",
    "        print(\"trainiere LDA Model mit \", int(num_topics),\" Topics\")    \n",
    "        lda = gensim.models.ldamulticore.LdaMulticore(\n",
    "                                corpus=train_corpus,\n",
    "                                num_topics=num_topics,\n",
    "                                id2word=train_id2w,\n",
    "                                chunksize=1000,\n",
    "                                workers=10, # Num. Processing Cores - 1\n",
    "                                passes=30,\n",
    "                                eval_every = 6,\n",
    "                                per_word_topics=False)\n",
    "        df_test[\"topic\"] = df_test[\"combined\"].apply(lambda x: get_topic(x , lda))\n",
    "        df_test[\"topic\"] = df_test[\"topic\"].astype(\"str\")\n",
    "        df_test[\"topic\"] = df_test[\"topic\"].replace(to_replace=r'[^\\d|\\.|\\,]', value='', regex=True)\n",
    "        df_test[\"topic\"] = df_test[\"topic\"].replace('', np.nan)\n",
    "        df_test[[\"topic\",\"certainty\"]] =  df_test[\"topic\"].progress_apply(lambda x: pd.Series(str(x).split(\",\")))\n",
    "        count_series =  df_test.groupby(['class','topic'])['class'].count()\n",
    "        count_series = count_series.to_frame()\n",
    "        count_series.columns = ['count']\n",
    "        count_series = count_series.reset_index()\n",
    "        print(\"Anzahl der Publiktationen pro Klasse:\" ,int(lowest_c), \" und \", int( num_topics),\" Topics\")\n",
    "        ax = sns.barplot(data=count_series,x=\"count\",  y=\"class\", orient=\"h\", hue=\"topic\")\n",
    "        ax.set(xlabel=\"Menge an Zugewiesenen Topics pro Klasse\",ylabel=\"Klasse(Averbis) & Topic(LDA)\")\n",
    "        ax.text(x=0.5, y=1.1, s='Klassifzierungsgenauigkeit des LDA Models anhand des Testdatensatzes',\n",
    "                fontsize=13, weight='bold',\n",
    "                ha='center', va='bottom', transform=ax.transAxes)\n",
    "        ax.text(x=0.5, y=1.05, s=\"bei einer Testdatensatzgröße von \" + str(len(df_test))+ \" Publikationen und \"+ str(num_topics)+' \"Topics\"',\n",
    "                fontsize=8, alpha=0.75, ha='center', va='bottom', transform=ax.transAxes)\n",
    "        \n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig(\"grafiken\\\\Klasse_zu_pub_\"+str(min_df_size)+\"_topics_\"+str(num_topics)+\".png\",dpi=300, bbox_inches = \"tight\") \n",
    "        fig.clf()\n",
    "        count_series.to_csv(\"lda_score_csv\\\\topic_population_at_\"+str(min_df_size)+\"_topics_\"+str(num_topics)+\".csv\")\n",
    "        num_topics = num_topics + 4\n",
    "\n",
    "    min_df_size = min_df_size*modi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
